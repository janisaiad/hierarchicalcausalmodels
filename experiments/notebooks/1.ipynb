{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys,os\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hierarchicalcausalmodels.models.HSCM.HSCM import HSCM # type: ignore\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, expon\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Define the HSCM model structure\n",
    "nodes = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "edges = [(\"a\", \"b\"), ('a', 'c'), (\"b\", \"c\"), (\"c\", \"d\"), (\"b\", \"d\"), (\"d\", \"e\"), (\"b\", \"e\")]\n",
    "unit_nodes = [\"a\", \"c\", \"e\"]\n",
    "subunit_nodes = [\"d\", \"b\"]\n",
    "sizes = [150] * 500  # You can adjust this based on your data\n",
    "\n",
    "# Initialize the HSCM model\n",
    "hscm = HSCM(nodes, edges, unit_nodes, subunit_nodes, sizes, node_functions={}, data=None)\n",
    "\n",
    "# Define random functions for each node\n",
    "random_functions = {\n",
    "    \"a\": lambda x: norm.ppf(x, 0, 1),\n",
    "    \"b\": lambda x: expon.ppf(x, 0, 1),\n",
    "    \"c\": lambda x: norm.ppf(x, 0, 1),\n",
    "    \"d\": lambda x: norm.ppf(x, 0, 1),\n",
    "    \"e\": lambda x: norm.ppf(x, 0, 1)\n",
    "}\n",
    "\n",
    "# Define additive functions for each node\n",
    "additive_functions = {\n",
    "    \"a\": {},\n",
    "    \"b\": {\"a\": lambda a: a * 0.1},\n",
    "    \"c\": {\"a\": lambda a: a * 0.1, \"b\": lambda b: np.mean(np.array(list(b))) * 0.1},\n",
    "    \"d\": {\"b\": lambda b: b * 3, \"c\": lambda c: c * 2},\n",
    "    \"e\": {\"d\": lambda d: np.mean(np.array(list(d))) * 0.1, \"b\": lambda b: np.mean(np.log(np.array(list(b))))}\n",
    "}\n",
    "\n",
    "# Set up the HSCM model\n",
    "hscm.additive_model(additive_functions, random_functions)\n",
    "\n",
    "# Sample data from the model\n",
    "sampled_data = hscm.sample_data()\n",
    "\n",
    "# Plot the sampled data\n",
    "hscm.plot_data()\n",
    "\n",
    "# Set distributions from the loaded data\n",
    "hscm.set_distribution_from_data()\n",
    "\n",
    "# Perform additional analysis or modify the model as needed\n",
    "# For example, you can change the graph structure or random functions here\n",
    "\n",
    "# Re-sample data after modifications\n",
    "new_sampled_data = hscm.sample_data()\n",
    "\n",
    "# Plot the new sampled data\n",
    "hscm.plot_data()\n",
    "\n",
    "# Compare the original and new sampled data\n",
    "for node in nodes:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist([sampled_data[node + str(i)] for i in range(len(sizes))], bins='auto', alpha=0.7, color='b')\n",
    "    plt.title(f\"Original {node}\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist([new_sampled_data[node + str(i)] for i in range(len(sizes))], bins='auto', alpha=0.7, color='r')\n",
    "    plt.title(f\"Modified {node}\")\n",
    "    plt.show()\n",
    "\n",
    "# Perform any additional analysis or visualization as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... (previous code remains the same)\n",
    "\n",
    "# Add these imports at the beginning of your notebook\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to create scatter plots\n",
    "def plot_comparison(original, sampled, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(original[:, 0], original[:, 1], c='blue', alpha=0.5, label='Original')\n",
    "    plt.scatter(sampled[:, 0], sampled[:, 1], c='red', alpha=0.5, label='Sampled')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Prepare data for dimensionality reduction\n",
    "original_data = np.column_stack([data[f\"{node}{i}\"] for node in nodes for i in range(len(sizes))])\n",
    "sampled_data = np.column_stack([sampled_data[f\"{node}{i}\"] for node in nodes for i in range(len(sizes))])\n",
    "\n",
    "# Combine and scale the data\n",
    "combined_data = np.vstack((original_data, sampled_data))\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(combined_data)\n",
    "\n",
    "# Perform dimensionality reduction\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(scaled_data)\n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_result = tsne.fit_transform(scaled_data)\n",
    "\n",
    "# UMAP\n",
    "umap_reducer = UMAP(n_components=2, random_state=42)\n",
    "umap_result = umap_reducer.fit_transform(scaled_data)\n",
    "\n",
    "# Split results back into original and sampled\n",
    "n_original = original_data.shape[0]\n",
    "original_pca, sampled_pca = pca_result[:n_original], pca_result[n_original:]\n",
    "original_tsne, sampled_tsne = tsne_result[:n_original], tsne_result[n_original:]\n",
    "original_umap, sampled_umap = umap_result[:n_original], umap_result[n_original:]\n",
    "\n",
    "# Plot comparisons\n",
    "plot_comparison(original_pca, sampled_pca, \"PCA: Original vs Sampled Data\")\n",
    "plot_comparison(original_tsne, sampled_tsne, \"t-SNE: Original vs Sampled Data\")\n",
    "plot_comparison(original_umap, sampled_umap, \"UMAP: Original vs Sampled Data\")\n",
    "\n",
    "# ... (rest of the previous code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add these imports at the beginning of your notebook\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def evaluate_generated_data(original_data, generated_data):\n",
    "    # Combine original and generated data\n",
    "    X = np.vstack((original_data, generated_data))\n",
    "    y = np.hstack((np.zeros(len(original_data)), np.ones(len(generated_data))))\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train a Random Forest classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    y_pred_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "    # Plot ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Random Classifier')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Precision-Recall curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, label='Precision-Recall Curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate the initial sampled data\n",
    "print(\"Evaluating initial sampled data:\")\n",
    "evaluate_generated_data(original_data, sampled_data)\n",
    "\n",
    "# After modifying the model and generating new_sampled_data\n",
    "print(\"\\nEvaluating new sampled data:\")\n",
    "evaluate_generated_data(original_data, new_sampled_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
